#!/usr/bin/env python3
"""
SmolVLAå¾®è°ƒè„šæœ¬ - RTX 3060 8GBæ˜¾å­˜ä¼˜åŒ–ç‰ˆæœ¬
ç›®æ ‡: åœ¨SO100 pick-placeæ•°æ®é›†ä¸Šå¾®è°ƒåŸºç¡€æ¨¡å‹

ä¼˜åŒ–ç­–ç•¥:
- å°æ‰¹é‡ (batch_size=4)
- æ¢¯åº¦ç´¯ç§¯ (accumulation=8, ç›¸å½“äºbatch=32)
- æ··åˆç²¾åº¦è®­ç»ƒ (FP16)
- å†»ç»“VLMï¼Œåªè®­ç»ƒAction Expert
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path
from datetime import datetime
import json
from tqdm import tqdm

# æ·»åŠ lerobotåˆ°è·¯å¾„
lerobot_path = Path("/root/lerobot_project/lerobot/src")
if str(lerobot_path) not in sys.path:
    sys.path.insert(0, str(lerobot_path))

from lerobot.datasets.lerobot_dataset import LeRobotDataset
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
from torch.cuda.amp import autocast, GradScaler

# ============= é…ç½®å‚æ•° =============
class Config:
    """è®­ç»ƒé…ç½®"""
    # æ¨¡å‹é…ç½®
    model_name = "lerobot/smolvla_base"
    
    # æ•°æ®é›†é…ç½®
    dataset_repo_id = "lerobot/svla_so100_pickplace"
    task_description = "Pick up the cube and place it in the box."
    
    # è®­ç»ƒé…ç½® - 8GBæ˜¾å­˜ä¼˜åŒ–
    batch_size = 4              # å°æ‰¹é‡
    gradient_accumulation_steps = 8  # ç´¯ç§¯æ¢¯åº¦ï¼Œç›¸å½“äºbatch=32
    num_steps = 20000           # æ€»è®­ç»ƒæ­¥æ•°
    
    # å­¦ä¹ ç‡é…ç½®
    learning_rate = 1e-4
    warmup_steps = 1000
    
    # ä¼˜åŒ–é…ç½®
    use_amp = True              # æ··åˆç²¾åº¦
    freeze_vlm = True           # å†»ç»“VLMï¼Œåªè®­ç»ƒAction Expert
    grad_clip_norm = 1.0        # æ¢¯åº¦è£å‰ª
    
    # ä¿å­˜é…ç½®
    save_freq = 2000            # æ¯2000æ­¥ä¿å­˜ä¸€æ¬¡
    eval_freq = 1000            # æ¯1000æ­¥è¯„ä¼°ä¸€æ¬¡
    log_freq = 100              # æ¯100æ­¥æ‰“å°æ—¥å¿—
    
    # è¾“å‡ºé…ç½®
    output_dir = "/root/lerobot_project/02-åœ¨3060-8Gä¸Šæµ‹è¯•å¾®è°ƒSO100/outputs"
    
    # è®¾å¤‡é…ç½®
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    def __init__(self):
        self.run_name = f"smolvla_so100_finetune_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.checkpoint_dir = Path(self.output_dir) / self.run_name
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)

# ============= å·¥å…·å‡½æ•° =============
def print_gpu_memory():
    """æ‰“å°GPUæ˜¾å­˜ä½¿ç”¨æƒ…å†µ"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        print(f"ğŸ“Š GPUæ˜¾å­˜: å·²åˆ†é…={allocated:.2f}GB, å·²ä¿ç•™={reserved:.2f}GB")

def save_config(config: Config):
    """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
    config_dict = {k: v for k, v in config.__dict__.items() 
                   if not k.startswith('_') and not callable(v)}
    config_dict['checkpoint_dir'] = str(config_dict['checkpoint_dir'])
    
    config_file = config.checkpoint_dir / "config.json"
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config_dict, f, indent=2, ensure_ascii=False)
    print(f"âœ… é…ç½®å·²ä¿å­˜åˆ°: {config_file}")

def save_checkpoint(policy, optimizer, scaler, step, config: Config):
    """ä¿å­˜æ£€æŸ¥ç‚¹"""
    checkpoint_path = config.checkpoint_dir / f"checkpoint_step_{step}.pt"
    
    torch.save({
        'step': step,
        'policy_state_dict': policy.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'scaler_state_dict': scaler.state_dict() if config.use_amp else None,
        'config': config.__dict__
    }, checkpoint_path)
    
    print(f"ğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_path}")
    return checkpoint_path

# ============= ä¸»è®­ç»ƒå‡½æ•° =============
def main():
    print("=" * 80)
    print("ğŸ¤– SmolVLAå¾®è°ƒè„šæœ¬ - 8GBæ˜¾å­˜ä¼˜åŒ–ç‰ˆ")
    print("=" * 80)
    
    # åˆå§‹åŒ–é…ç½®
    config = Config()
    save_config(config)
    
    print(f" è®­ç»ƒé…ç½®:")
    print(f"  - æ¨¡å‹: {config.model_name}")
    print(f"  - æ•°æ®é›†: {config.dataset_repo_id}")
    print(f"  - æ‰¹é‡å¤§å°: {config.batch_size} (ç´¯ç§¯={config.gradient_accumulation_steps}, æœ‰æ•ˆ={config.batch_size * config.gradient_accumulation_steps})")
    print(f"  - è®­ç»ƒæ­¥æ•°: {config.num_steps}")
    print(f"  - å­¦ä¹ ç‡: {config.learning_rate}")
    print(f"  - æ··åˆç²¾åº¦: {config.use_amp}")
    print(f"  - å†»ç»“VLM: {config.freeze_vlm}")
    print(f"  - è®¾å¤‡: {config.device}")
    print(f"  - è¾“å‡ºç›®å½•: {config.checkpoint_dir}")
    
    # æ£€æŸ¥GPU
    if not torch.cuda.is_available():
        print("âŒ æœªæ£€æµ‹åˆ°GPUï¼Œè®­ç»ƒå°†éå¸¸ç¼“æ…¢!")
        return
    
    print(f" GPUä¿¡æ¯:")
    print(f"  - è®¾å¤‡åç§°: {torch.cuda.get_device_name(0)}")
    print(f"  - æ€»æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
    print_gpu_memory()
    
    # 1. åŠ è½½æ•°æ®é›†
    print(f"åŠ è½½æ•°æ®é›†: {config.dataset_repo_id}")
    try:
        dataset = LeRobotDataset(
            repo_id=config.dataset_repo_id,
            root="/tmp/lerobot_datasets",  # ä¸´æ—¶ç¼“å­˜ç›®å½•
        )
        print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ: {len(dataset)} ä¸ªæ ·æœ¬")
        print(f"  - Episodes: {dataset.num_episodes}")
        print(f"  - åŠ¨ä½œç»´åº¦: {dataset.meta.action_dim}")
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        return
    
    # 2. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print(f"åˆ›å»ºæ•°æ®åŠ è½½å™¨ (batch_size={config.batch_size})")
    from torch.utils.data import DataLoader
    
    dataloader = DataLoader(
        dataset,
        batch_size=config.batch_size,
        shuffle=True,
        num_workers=2,
        pin_memory=True,
    )
    
    # 3. åŠ è½½æ¨¡å‹
    print(f"åŠ è½½æ¨¡å‹: {config.model_name}")
    try:
        policy = SmolVLAPolicy.from_pretrained(config.model_name)
        policy = policy.to(config.device)
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # ç»Ÿè®¡å‚æ•°
        total_params = sum(p.numel() for p in policy.parameters())
        trainable_params = sum(p.numel() for p in policy.parameters() if p.requires_grad)
        print(f"  - æ€»å‚æ•°: {total_params / 1e6:.1f}M")
        print(f"  - å¯è®­ç»ƒå‚æ•°: {trainable_params / 1e6:.1f}M")
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # 4. å†»ç»“VLM (å¯é€‰ï¼ŒèŠ‚çœæ˜¾å­˜)
    if config.freeze_vlm:
        print(f"å†»ç»“VLMï¼Œåªè®­ç»ƒAction Expert")
        for name, param in policy.named_parameters():
            if 'action_expert' not in name:
                param.requires_grad = False
        
        trainable_params = sum(p.numel() for p in policy.parameters() if p.requires_grad)
        print(f"  - å†»ç»“åå¯è®­ç»ƒå‚æ•°: {trainable_params / 1e6:.1f}M")
    
    print_gpu_memory()
    
    # 5. åˆ›å»ºä¼˜åŒ–å™¨
    print(f"åˆ›å»ºä¼˜åŒ–å™¨ (lr={config.learning_rate})")
    optimizer = torch.optim.AdamW(
        [p for p in policy.parameters() if p.requires_grad],
        lr=config.learning_rate,
        weight_decay=0.01
    )
    
    # 6. å­¦ä¹ ç‡è°ƒåº¦å™¨
    from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
    scheduler = CosineAnnealingWarmRestarts(
        optimizer,
        T_0=config.num_steps // 4,  # é‡å¯å‘¨æœŸ
        T_mult=1,
        eta_min=config.learning_rate * 0.1
    )
    
    # 7. æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = GradScaler(enabled=config.use_amp)
    
    # 8. è®­ç»ƒå¾ªç¯
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ ({config.num_steps} æ­¥)")
    print("=" * 80)
    
    policy.train()
    global_step = 0
    epoch = 0
    total_loss = 0.0
    optimizer.zero_grad()
    
    # åˆ›å»ºæ—¥å¿—æ–‡ä»¶
    log_file = config.checkpoint_dir / "training_log.txt"
    
    try:
        while global_step < config.num_steps:
            epoch += 1
            print(f"ğŸ“š Epoch {epoch}")
            
            for batch_idx, batch in enumerate(tqdm(dataloader, desc=f"Epoch {epoch}")):
                # å°†batchç§»åˆ°GPU
                batch = {k: v.to(config.device) if isinstance(v, torch.Tensor) else v 
                        for k, v in batch.items()}
                
                # å‰å‘ä¼ æ’­ (ä½¿ç”¨æ··åˆç²¾åº¦)
                with autocast(enabled=config.use_amp):
                    loss, output_dict = policy.forward(batch)
                    loss = loss / config.gradient_accumulation_steps  # ç¼©æ”¾æŸå¤±
                
                # åå‘ä¼ æ’­
                scaler.scale(loss).backward()
                
                # æ¢¯åº¦ç´¯ç§¯
                if (batch_idx + 1) % config.gradient_accumulation_steps == 0:
                    # æ¢¯åº¦è£å‰ª
                    if config.grad_clip_norm > 0:
                        scaler.unscale_(optimizer)
                        torch.nn.utils.clip_grad_norm_(policy.parameters(), config.grad_clip_norm)
                    
                    # æ›´æ–°å‚æ•°
                    scaler.step(optimizer)
                    scaler.update()
                    scheduler.step()
                    optimizer.zero_grad()
                    
                    global_step += 1
                    total_loss += loss.item() * config.gradient_accumulation_steps
                    
                    # æ‰“å°æ—¥å¿—
                    if global_step % config.log_freq == 0:
                        avg_loss = total_loss / config.log_freq
                        lr = scheduler.get_last_lr()[0]
                        
                        log_msg = f"Step {global_step}/{config.num_steps} | Loss: {avg_loss:.4f} | LR: {lr:.6f}"
                        print(f"  {log_msg}")
                        
                        # å†™å…¥æ—¥å¿—æ–‡ä»¶
                        with open(log_file, 'a') as f:
                            f.write(f"{datetime.now()}: {log_msg}")
                        
                        total_loss = 0.0
                        print_gpu_memory()
                    
                    # ä¿å­˜æ£€æŸ¥ç‚¹
                    if global_step % config.save_freq == 0:
                        print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹ (æ­¥æ•°: {global_step})")
                        save_checkpoint(policy, optimizer, scaler, global_step, config)
                    
                    # è¾¾åˆ°ç›®æ ‡æ­¥æ•°
                    if global_step >= config.num_steps:
                        break
            
            if global_step >= config.num_steps:
                break
    
    except KeyboardInterrupt:
        print(f"âš ï¸ è®­ç»ƒè¢«ä¸­æ–­ (æ­¥æ•°: {global_step})")
        print(f"ä¿å­˜å½“å‰æ£€æŸ¥ç‚¹...")
        save_checkpoint(policy, optimizer, scaler, global_step, config)
    
    except Exception as e:
        print(f"âŒ è®­ç»ƒå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 9. ä¿å­˜æœ€ç»ˆæ¨¡å‹
    print(f"ğŸ‰ è®­ç»ƒå®Œæˆ!")
    print(f"  - æ€»æ­¥æ•°: {global_step}")
    print(f"  - æ€»Epochs: {epoch}")
    
    final_path = config.checkpoint_dir / "final_model.pt"
    save_checkpoint(policy, optimizer, scaler, global_step, config)
    
    # ä¿å­˜ä¸ºHuggingFaceæ ¼å¼
    print(f"ğŸ’¾ ä¿å­˜HuggingFaceæ ¼å¼æ¨¡å‹...")
    hf_save_path = config.checkpoint_dir / "huggingface_model"
    policy.save_pretrained(hf_save_path)
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {hf_save_path}")
    
    print(f"âœ¨ æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨: {config.checkpoint_dir}")
    print("=" * 80)

if __name__ == "__main__":
    main()
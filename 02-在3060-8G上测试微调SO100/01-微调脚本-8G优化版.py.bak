#!/usr/bin/env python3
"""
SmolVLA微调脚本 - RTX 3060 8GB显存优化版本
目标: 在SO100 pick-place数据集上微调基础模型

优化策略:
- 小批量 (batch_size=4)
- 梯度累积 (accumulation=8, 相当于batch=32)
- 混合精度训练 (FP16)
- 冻结VLM，只训练Action Expert
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path
from datetime import datetime
import json
from tqdm import tqdm

# 添加lerobot到路径
lerobot_path = Path("/root/lerobot_project/lerobot/src")
if str(lerobot_path) not in sys.path:
    sys.path.insert(0, str(lerobot_path))

from lerobot.datasets.lerobot_dataset import LeRobotDataset
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
from torch.cuda.amp import autocast, GradScaler

# ============= 配置参数 =============
class Config:
    """训练配置"""
    # 模型配置
    model_name = "lerobot/smolvla_base"
    
    # 数据集配置
    dataset_repo_id = "lerobot/svla_so100_pickplace"
    task_description = "Pick up the cube and place it in the box."
    
    # 训练配置 - 8GB显存优化
    batch_size = 4              # 小批量
    gradient_accumulation_steps = 8  # 累积梯度，相当于batch=32
    num_steps = 20000           # 总训练步数
    
    # 学习率配置
    learning_rate = 1e-4
    warmup_steps = 1000
    
    # 优化配置
    use_amp = True              # 混合精度
    freeze_vlm = True           # 冻结VLM，只训练Action Expert
    grad_clip_norm = 1.0        # 梯度裁剪
    
    # 保存配置
    save_freq = 2000            # 每2000步保存一次
    eval_freq = 1000            # 每1000步评估一次
    log_freq = 100              # 每100步打印日志
    
    # 输出配置
    output_dir = "/root/lerobot_project/02-在3060-8G上测试微调SO100/outputs"
    
    # 设备配置
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    def __init__(self):
        self.run_name = f"smolvla_so100_finetune_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.checkpoint_dir = Path(self.output_dir) / self.run_name
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)

# ============= 工具函数 =============
def print_gpu_memory():
    """打印GPU显存使用情况"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        print(f"📊 GPU显存: 已分配={allocated:.2f}GB, 已保留={reserved:.2f}GB")

def save_config(config: Config):
    """保存配置到文件"""
    config_dict = {k: v for k, v in config.__dict__.items() 
                   if not k.startswith('_') and not callable(v)}
    config_dict['checkpoint_dir'] = str(config_dict['checkpoint_dir'])
    
    config_file = config.checkpoint_dir / "config.json"
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(config_dict, f, indent=2, ensure_ascii=False)
    print(f"✅ 配置已保存到: {config_file}")

def save_checkpoint(policy, optimizer, scaler, step, config: Config):
    """保存检查点"""
    checkpoint_path = config.checkpoint_dir / f"checkpoint_step_{step}.pt"
    
    torch.save({
        'step': step,
        'policy_state_dict': policy.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'scaler_state_dict': scaler.state_dict() if config.use_amp else None,
        'config': config.__dict__
    }, checkpoint_path)
    
    print(f"💾 检查点已保存: {checkpoint_path}")
    return checkpoint_path

# ============= 主训练函数 =============
def main():
    print("=" * 80)
    print("🤖 SmolVLA微调脚本 - 8GB显存优化版")
    print("=" * 80)
    
    # 初始化配置
    config = Config()
    save_config(config)
    
    print(f" 训练配置:")
    print(f"  - 模型: {config.model_name}")
    print(f"  - 数据集: {config.dataset_repo_id}")
    print(f"  - 批量大小: {config.batch_size} (累积={config.gradient_accumulation_steps}, 有效={config.batch_size * config.gradient_accumulation_steps})")
    print(f"  - 训练步数: {config.num_steps}")
    print(f"  - 学习率: {config.learning_rate}")
    print(f"  - 混合精度: {config.use_amp}")
    print(f"  - 冻结VLM: {config.freeze_vlm}")
    print(f"  - 设备: {config.device}")
    print(f"  - 输出目录: {config.checkpoint_dir}")
    
    # 检查GPU
    if not torch.cuda.is_available():
        print("❌ 未检测到GPU，训练将非常缓慢!")
        return
    
    print(f" GPU信息:")
    print(f"  - 设备名称: {torch.cuda.get_device_name(0)}")
    print(f"  - 总显存: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
    print_gpu_memory()
    
    # 1. 加载数据集
    print(f"加载数据集: {config.dataset_repo_id}")
    try:
        dataset = LeRobotDataset(
            repo_id=config.dataset_repo_id,
            root="/tmp/lerobot_datasets",  # 临时缓存目录
        )
        print(f"✅ 数据集加载成功: {len(dataset)} 个样本")
        print(f"  - Episodes: {dataset.num_episodes}")
        print(f"  - 动作维度: {dataset.meta.action_dim}")
    except Exception as e:
        print(f"❌ 数据集加载失败: {e}")
        return
    
    # 2. 创建数据加载器
    print(f"创建数据加载器 (batch_size={config.batch_size})")
    from torch.utils.data import DataLoader
    
    dataloader = DataLoader(
        dataset,
        batch_size=config.batch_size,
        shuffle=True,
        num_workers=2,
        pin_memory=True,
    )
    
    # 3. 加载模型
    print(f"加载模型: {config.model_name}")
    try:
        policy = SmolVLAPolicy.from_pretrained(config.model_name)
        policy = policy.to(config.device)
        print(f"✅ 模型加载成功")
        
        # 统计参数
        total_params = sum(p.numel() for p in policy.parameters())
        trainable_params = sum(p.numel() for p in policy.parameters() if p.requires_grad)
        print(f"  - 总参数: {total_params / 1e6:.1f}M")
        print(f"  - 可训练参数: {trainable_params / 1e6:.1f}M")
        
    except Exception as e:
        print(f"❌ 模型加载失败: {e}")
        return
    
    # 4. 冻结VLM (可选，节省显存)
    if config.freeze_vlm:
        print(f"冻结VLM，只训练Action Expert")
        for name, param in policy.named_parameters():
            if 'action_expert' not in name:
                param.requires_grad = False
        
        trainable_params = sum(p.numel() for p in policy.parameters() if p.requires_grad)
        print(f"  - 冻结后可训练参数: {trainable_params / 1e6:.1f}M")
    
    print_gpu_memory()
    
    # 5. 创建优化器
    print(f"创建优化器 (lr={config.learning_rate})")
    optimizer = torch.optim.AdamW(
        [p for p in policy.parameters() if p.requires_grad],
        lr=config.learning_rate,
        weight_decay=0.01
    )
    
    # 6. 学习率调度器
    from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
    scheduler = CosineAnnealingWarmRestarts(
        optimizer,
        T_0=config.num_steps // 4,  # 重启周期
        T_mult=1,
        eta_min=config.learning_rate * 0.1
    )
    
    # 7. 混合精度训练
    scaler = GradScaler(enabled=config.use_amp)
    
    # 8. 训练循环
    print(f"🚀 开始训练 ({config.num_steps} 步)")
    print("=" * 80)
    
    policy.train()
    global_step = 0
    epoch = 0
    total_loss = 0.0
    optimizer.zero_grad()
    
    # 创建日志文件
    log_file = config.checkpoint_dir / "training_log.txt"
    
    try:
        while global_step < config.num_steps:
            epoch += 1
            print(f"📚 Epoch {epoch}")
            
            for batch_idx, batch in enumerate(tqdm(dataloader, desc=f"Epoch {epoch}")):
                # 将batch移到GPU
                batch = {k: v.to(config.device) if isinstance(v, torch.Tensor) else v 
                        for k, v in batch.items()}
                
                # 前向传播 (使用混合精度)
                with autocast(enabled=config.use_amp):
                    loss, output_dict = policy.forward(batch)
                    loss = loss / config.gradient_accumulation_steps  # 缩放损失
                
                # 反向传播
                scaler.scale(loss).backward()
                
                # 梯度累积
                if (batch_idx + 1) % config.gradient_accumulation_steps == 0:
                    # 梯度裁剪
                    if config.grad_clip_norm > 0:
                        scaler.unscale_(optimizer)
                        torch.nn.utils.clip_grad_norm_(policy.parameters(), config.grad_clip_norm)
                    
                    # 更新参数
                    scaler.step(optimizer)
                    scaler.update()
                    scheduler.step()
                    optimizer.zero_grad()
                    
                    global_step += 1
                    total_loss += loss.item() * config.gradient_accumulation_steps
                    
                    # 打印日志
                    if global_step % config.log_freq == 0:
                        avg_loss = total_loss / config.log_freq
                        lr = scheduler.get_last_lr()[0]
                        
                        log_msg = f"Step {global_step}/{config.num_steps} | Loss: {avg_loss:.4f} | LR: {lr:.6f}"
                        print(f"  {log_msg}")
                        
                        # 写入日志文件
                        with open(log_file, 'a') as f:
                            f.write(f"{datetime.now()}: {log_msg}")
                        
                        total_loss = 0.0
                        print_gpu_memory()
                    
                    # 保存检查点
                    if global_step % config.save_freq == 0:
                        print(f"💾 保存检查点 (步数: {global_step})")
                        save_checkpoint(policy, optimizer, scaler, global_step, config)
                    
                    # 达到目标步数
                    if global_step >= config.num_steps:
                        break
            
            if global_step >= config.num_steps:
                break
    
    except KeyboardInterrupt:
        print(f"⚠️ 训练被中断 (步数: {global_step})")
        print(f"保存当前检查点...")
        save_checkpoint(policy, optimizer, scaler, global_step, config)
    
    except Exception as e:
        print(f"❌ 训练出错: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 9. 保存最终模型
    print(f"🎉 训练完成!")
    print(f"  - 总步数: {global_step}")
    print(f"  - 总Epochs: {epoch}")
    
    final_path = config.checkpoint_dir / "final_model.pt"
    save_checkpoint(policy, optimizer, scaler, global_step, config)
    
    # 保存为HuggingFace格式
    print(f"💾 保存HuggingFace格式模型...")
    hf_save_path = config.checkpoint_dir / "huggingface_model"
    policy.save_pretrained(hf_save_path)
    print(f"✅ 模型已保存到: {hf_save_path}")
    
    print(f"✨ 所有文件保存在: {config.checkpoint_dir}")
    print("=" * 80)

if __name__ == "__main__":
    main()
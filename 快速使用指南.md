# SmolVLA 快速使用指南

## 🚀 5分钟快速开始

### 1. 激活环境
```bash
conda activate smolvla
cd /root/smolvla_project
```

### 2. 运行测试
```bash
# 运行完整测试（推荐）
python test_final_working.py

# 预期输出：
# ✅ 推理成功!
#    输出形状: torch.Size([1, 6])
#    推理时间: 5 ms
#    控制频率: ~182.5 Hz
```

### 3. 使用模型

创建 `my_robot_control.py`：

```python
import sys
import torch
from transformers import AutoTokenizer

sys.path.insert(0, '/root/smolvla_project/lerobot/src')
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy

# 加载模型（一次性）
device = "cuda"
policy = SmolVLAPolicy.from_pretrained("lerobot/smolvla_base")
policy = policy.to(device).float().eval()

tokenizer = AutoTokenizer.from_pretrained("HuggingFaceTB/SmolVLM2-500M-Video-Instruct")

# 控制循环
while True:
    # 1. 获取机器人传感器数据
    camera1_image = get_camera1()  # 你的函数，返回 (3,256,256) tensor
    camera2_image = get_camera2()
    camera3_image = get_camera3()
    robot_state = get_robot_state()  # 返回 (14,) tensor
    
    # 2. 准备指令
    instruction = "Pick up the red block"
    tokens = tokenizer(instruction, return_tensors="pt")
    
    # 3. 构造 batch
    batch = {
        "observation.images.camera1": camera1_image.unsqueeze(0).to(device),  # 添加 batch 维度
        "observation.images.camera2": camera2_image.unsqueeze(0).to(device),
        "observation.images.camera3": camera3_image.unsqueeze(0).to(device),
        "observation.state": robot_state.unsqueeze(0).to(device),
        "observation.language.tokens": tokens['input_ids'].to(device),
        "observation.language.attention_mask": tokens['attention_mask'].to(device).bool(),  # 必须 bool!
    }
    
    # 4. 推理
    with torch.no_grad():
        action = policy.select_action(batch)
    
    # 5. 执行动作
    execute_action(action.squeeze(0).cpu().numpy())  # 去掉 batch 维度
```

## 📝 常见问题 FAQ

### Q1: 为什么推理时间第一次很慢？
**A**: 首次推理需要初始化模型和缓存，约 1000ms。后续推理从队列取动作，只需 5ms。

### Q2: 输出为什么是 6 维而不是 7 维？
**A**: 这是模型的正常行为，6 维足够用于机械臂控制（位置3维+旋转3维）。

### Q3: 必须提供 3 个相机吗？
**A**: 是的，这是模型配置要求。如果只有 1 个相机，可以复制 3 份：
```python
image = get_camera()
batch = {
    "observation.images.camera1": image,
    "observation.images.camera2": image,  # 复制
    "observation.images.camera3": image,  # 复制
    ...
}
```

### Q4: 如何更改状态维度？
**A**: 状态维度取决于你的机器人。ALOHA 使用 14 维，PushT 使用 7 维。调整相应的输入即可。

### Q5: attention_mask 为什么必须是 bool？
**A**: PyTorch 的 `torch.where` 要求条件必须是 bool 类型，否则会报错。使用 `.bool()` 转换。

## 🔧 故障排查

### 错误 1: `TypeError: got an unexpected keyword argument 'torch_dtype'`
**解决**: 不要传 `torch_dtype` 和 `device` 给 `from_pretrained()`，改用 `.to(device).float()`

### 错误 2: `RuntimeError: where expected condition to be a boolean tensor`
**解决**: `attention_mask` 转为 bool - `tokens['attention_mask'].to(device).bool()`

### 错误 3: `ValueError: (b,c,h,w) expected`
**解决**: 图像需要 batch 维度 - `image.unsqueeze(0)` 添加维度

### 错误 4: `KeyError: 'observation.language.tokens'`
**解决**: 确保提供了语言 tokens 和 attention_mask

### 错误 5: `ModuleNotFoundError: No module named 'draccus'`
**解决**: `pip install draccus datasets==3.6.0`

## 📊 性能优化建议

1. **使用 GPU**: 确保在 CUDA 上运行，速度提升 100x
2. **批处理**: 如果有多个请求，可以批处理提升效率
3. **固定指令**: 如果指令不变，可以预先 tokenize
4. **图像预处理**: 提前将图像转为正确格式和设备

## 📚 相关文件

- `test_final_working.py` - 完整工作测试 ⭐
- `修复完整总结.md` - 详细修复文档
- `download_and_test_dataset.py` - 数据集下载和测试

## 💡 小贴士

1. 在 smolvla 环境中运行
2. attention_mask 必须转 bool
3. 所有输入都需要 batch 维度
4. 首次推理慢是正常的
5. 后续推理速度快（约 5ms）

---

**最后更新**: 2025-10-20  
**状态**: ✅ 所有问题已修复，可用于生产

#!/usr/bin/env python3
"""SmolVLA å®Œæ•´å·¥ä½œæµ‹è¯• - æ‰€æœ‰é—®é¢˜å·²ä¿®å¤"""

import sys
import torch
import numpy as np
import time

sys.path.insert(0, '/root/smolvla_project/lerobot/src')

print("\n" + "="*60)
print("SmolVLA å®Œæ•´æµ‹è¯• - æ‰€æœ‰ä¿®å¤å·²åº”ç”¨")
print("="*60 + "\n")

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"è®¾å¤‡: {device}")

# 1. åŠ è½½æ¨¡å‹
print("\n[1/3] åŠ è½½æ¨¡å‹...")
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy

# âœ… ä¿®å¤1: ä¸ä¼  torch_dtype å’Œ device
policy = SmolVLAPolicy.from_pretrained("lerobot/smolvla_base")
policy = policy.to(device).float()  # âœ… ä¿®å¤2: æ‰‹åŠ¨è®¾ç½®ï¼Œä½¿ç”¨ float32
policy.eval()
print("âœ… åŠ è½½æˆåŠŸ")

# 2. å‡†å¤‡è¾“å…¥
print("\n[2/3] å‡†å¤‡è¾“å…¥...")
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("HuggingFaceTB/SmolVLM2-500M-Video-Instruct")
instruction = "Pick up the red block and place it in the box"
tokens = tokenizer(instruction, return_tensors="pt")

# âœ… ä¿®å¤3: attention_mask è½¬ä¸º bool ç±»å‹
batch = {
    "observation.images.camera1": torch.randn(1, 3, 256, 256).to(device),
    "observation.images.camera2": torch.randn(1, 3, 256, 256).to(device),
    "observation.images.camera3": torch.randn(1, 3, 256, 256).to(device),
    "observation.state": torch.randn(1, 14).to(device),
    "observation.language.tokens": tokens['input_ids'].to(device),
    "observation.language.attention_mask": tokens['attention_mask'].to(device).bool(),  # âœ… å…³é”®ä¿®å¤!
}

print(f"  å›¾åƒ: 3ä¸ªè§†è§’ (1,3,256,256)")
print(f"  çŠ¶æ€: (1,14)")
print(f"  æŒ‡ä»¤: '{instruction}'")
print(f"  attention_maskç±»å‹: {batch['observation.language.attention_mask'].dtype}")  # åº”è¯¥æ˜¯ bool

# 3. æ¨ç†
print("\n[3/3] æ¨ç†æµ‹è¯•...")
start = time.time()
with torch.no_grad():
    action = policy.select_action(batch)
time_ms = (time.time() - start) * 1000

print(f"\nâœ… æ¨ç†æˆåŠŸ!")
print(f"   è¾“å‡ºå½¢çŠ¶: {action.shape}")
print(f"   åŠ¨ä½œç»´åº¦: {action.shape[-1]}")
print(f"   åŠ¨ä½œèŒƒå›´: [{action.min().item():.3f}, {action.max().item():.3f}]")
print(f"   æ¨ç†æ—¶é—´: {time_ms:.0f} ms")

# æ€§èƒ½æµ‹è¯•
print(f"\næ€§èƒ½æµ‹è¯•ï¼ˆ20æ¬¡ï¼‰...")
times = []
for i in range(20):
    start = time.time()
    with torch.no_grad():
        _ = policy.select_action(batch)
    times.append((time.time() - start) * 1000)
    if (i + 1) % 5 == 0:
        print(f"  è¿›åº¦: {i+1}/20")

print(f"\næ€§èƒ½ç»Ÿè®¡:")
print(f"  å¹³å‡: {np.mean(times):.0f} ms")
print(f"  ä¸­ä½æ•°: {np.median(times):.0f} ms")
print(f"  æœ€å°: {np.min(times):.0f} ms")
print(f"  æœ€å¤§: {np.max(times):.0f} ms")
print(f"  æ§åˆ¶é¢‘ç‡: ~{1000/np.mean(times):.1f} Hz")

# æ€»ç»“
print(f"\n" + "="*60)
print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡! é—®é¢˜å…¨éƒ¨ä¿®å¤!")
print("="*60)

print("\nå…³é”®ä¿®å¤æ±‡æ€»:")
print("  1. âœ… from_pretrained() ä¸ä¼  torch_dtype/device")
print("  2. âœ… ä½¿ç”¨ .to(device).float() æ‰‹åŠ¨è®¾ç½®")
print("  3. âœ… attention_mask è½¬ä¸º bool ç±»å‹")
print("  4. âœ… å›¾åƒ batch ç»´åº¦: (1,3,256,256)")
print("  5. âœ… æ­£ç¡®çš„é”®åæ ¼å¼")

print("\nå®Œæ•´è¾“å…¥æ ¼å¼:")
print("  observation.images.camera1/2/3: torch.Tensor (1,3,256,256)")
print("  observation.state: torch.Tensor (1,14)")
print("  observation.language.tokens: torch.Tensor (1,seq_len)")
print("  observation.language.attention_mask: torch.BoolTensor (1,seq_len)")

print(f"\nğŸ’¡ è¿™ä¸ªè„šæœ¬å¯ä»¥ç›´æ¥ç”¨äºç”Ÿäº§ç¯å¢ƒ!")
print("")


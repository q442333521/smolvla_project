"""
SmolVLA å®Œæ•´æµ‹è¯• - å±•ç¤ºä¸¤ç§æ¨ç†æ¨¡å¼
"""

import torch
import numpy as np
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
from transformers import AutoTokenizer
import time

print("ğŸš€ SmolVLA å®Œæ•´æ¨ç†æµ‹è¯•\n")

# åŠ è½½æ¨¡å‹
print("åŠ è½½æ¨¡å‹...")
policy = SmolVLAPolicy.from_pretrained("lerobot/smolvla_base")
policy = policy.to("cuda").float().eval()

print(f"âœ… æ¨¡å‹åŠ è½½ ({sum(p.numel() for p in policy.parameters()) / 1e6:.1f}Må‚æ•°)")
print(f"   æ•°æ®ç±»å‹: {next(policy.parameters()).dtype}")
print(f"   n_action_steps: {policy.config.n_action_steps}\n")

# åŠ è½½tokenizer
tokenizer = AutoTokenizer.from_pretrained(policy.config.vlm_model_name)
print("âœ… TokenizeråŠ è½½\n")

# å‡†å¤‡è¾“å…¥
image = torch.rand(1, 3, 256, 256).cuda().float()
state = torch.randn(1, 7).cuda().float()
instruction = "pick up the red cube"

tokens = tokenizer(
    instruction,
    return_tensors="pt",
    padding="max_length",
    truncation=True,
    max_length=77
)

observation = {
    "observation.images.camera1": image,
    "observation.state": state,
    "observation.language.tokens": tokens["input_ids"].cuda(),
    "observation.language.attention_mask": tokens["attention_mask"].cuda().bool(),
}

print(f"è¾“å…¥: å›¾åƒ{image.shape}, çŠ¶æ€{state.shape}, æŒ‡ä»¤'{instruction}'\n")

# ============================================================
# æ¨¡å¼1ï¼šè·å–å®Œæ•´åŠ¨ä½œåºåˆ—ï¼ˆç”¨äºåˆ†æï¼‰
# ============================================================
print("=" * 60)
print("æ¨¡å¼1ï¼šè·å–å®Œæ•´åŠ¨ä½œåºåˆ— (_get_action_chunk)")
print("=" * 60)

from lerobot.policies.utils import populate_queues
policy._queues = populate_queues(policy._queues, observation, exclude_keys=["action"])

print("æ¨ç†ä¸­...")
start = time.time()

with torch.no_grad():
    action_chunk = policy._get_action_chunk(observation, noise=None)

t = (time.time() - start) * 1000

print(f"âœ… å®Œæ•´åŠ¨ä½œåºåˆ—ç”ŸæˆæˆåŠŸï¼")
print(f"   æ—¶é—´: {t:.1f}ms")
print(f"   è¾“å‡ºå½¢çŠ¶: {action_chunk.shape} (batch, steps, dims)")
print(f"   èŒƒå›´: [{action_chunk.min().item():.3f}, {action_chunk.max().item():.3f}]")

# åˆ†æåŠ¨ä½œå¹³æ»‘æ€§
if action_chunk.shape[1] > 1:
    diff = torch.diff(action_chunk[0], dim=0)
    smoothness = diff.abs().mean().item()
    print(f"   åŠ¨ä½œå¹³æ»‘åº¦: {smoothness:.4f} (è¶Šå°è¶Šå¹³æ»‘)\n")

# ============================================================
# æ¨¡å¼2ï¼šé€æ­¥è·å–åŠ¨ä½œï¼ˆç”¨äºå®æ—¶æ§åˆ¶ï¼‰
# ============================================================
print("=" * 60)
print("æ¨¡å¼2ï¼šé€æ­¥è·å–åŠ¨ä½œ (select_action)")
print("=" * 60)

# é‡ç½®é˜Ÿåˆ—
policy._queues["action"].clear()

actions_list = []
times_list = []

print(f"é€æ­¥è·å– {policy.config.n_action_steps} ä¸ªåŠ¨ä½œ...")

for i in range(policy.config.n_action_steps):
    start = time.time()
    
    with torch.no_grad():
        action = policy.select_action(observation)
    
    t = (time.time() - start) * 1000
    times_list.append(t)
    actions_list.append(action.cpu().numpy())
    
    if (i + 1) % 20 == 0 or i == 0:
        print(f"  Step {i+1}: {t:.1f}ms, action shape: {action.shape}")

actions_array = np.array(actions_list)
print(f"\nâœ… é€æ­¥è·å–å®Œæˆ")
print(f"   æ€»æ­¥æ•°: {len(actions_list)}")
print(f"   å¹³å‡æ—¶é—´: {np.mean(times_list):.1f}ms/step")
print(f"   é¦–æ¬¡æ—¶é—´: {times_list[0]:.1f}ms (åŒ…å«æ¨ç†)")
print(f"   åç»­æ—¶é—´: {np.mean(times_list[1:]):.1f}ms (ä»é˜Ÿåˆ—å–)")
print(f"   åŠ¨ä½œå½¢çŠ¶: {actions_array.shape}\n")

# ============================================================
# é€Ÿåº¦åŸºå‡†æµ‹è¯•
# ============================================================
print("=" * 60)
print("æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼ˆ10æ¬¡å®Œæ•´æ¨ç†ï¼‰")
print("=" * 60)

times = []
for i in range(10):
    # æ¸…ç©ºé˜Ÿåˆ—
    policy._queues["action"].clear()
    
    obs = {
        "observation.images.camera1": torch.rand(1, 3, 256, 256).cuda().float(),
        "observation.state": torch.randn(1, 7).cuda().float(),
        "observation.language.tokens": tokens["input_ids"].cuda(),
        "observation.language.attention_mask": tokens["attention_mask"].cuda().bool(),
    }
    
    start = time.time()
    with torch.no_grad():
        _ = policy.select_action(obs)
    times.append((time.time() - start) * 1000)
    
    if (i + 1) % 5 == 0:
        print(f"  {i+1}/10 å®Œæˆ")

times = np.array(times)
print(f"\nâœ… åŸºå‡†æµ‹è¯•ç»“æœ:")
print(f"   å¹³å‡: {times.mean():.1f}ms")
print(f"   ä¸­ä½æ•°: {np.median(times):.1f}ms")
print(f"   æ ‡å‡†å·®: {times.std():.1f}ms")
print(f"   é¢‘ç‡: {1000/times.mean():.1f}Hz\n")

# æ˜¾å­˜
mem = torch.cuda.memory_allocated() / 1024**3
print(f"ğŸ’¾ æ˜¾å­˜: {mem:.2f}GB\n")

# ============================================================
# æ€»ç»“
# ============================================================
print("=" * 60)
print("ğŸ“Š éªŒæ”¶ç»“æœ")
print("=" * 60)

speed_ok = times.mean() < 150
freq_ok = 1000/times.mean() > 7
mem_ok = mem < 12

print(f"1. æ¨ç†é€Ÿåº¦: {times.mean():.1f}ms " + ("âœ… è¾¾æ ‡" if speed_ok else "âš ï¸  æœªè¾¾æ ‡"))
print(f"2. æ¨ç†é¢‘ç‡: {1000/times.mean():.1f}Hz " + ("âœ… è¾¾æ ‡" if freq_ok else "âš ï¸  æœªè¾¾æ ‡"))
print(f"3. æ˜¾å­˜å ç”¨: {mem:.2f}GB " + ("âœ… è¾¾æ ‡" if mem_ok else "âš ï¸  è¶…æ ‡"))
print(f"4. åŠ¨ä½œç»´åº¦: {action_chunk.shape} âœ…")
print(f"5. è¾“å‡ºæ­£å¸¸: " + ("âœ…" if not torch.isnan(action_chunk).any() else "âŒ"))

if speed_ok and freq_ok and mem_ok:
    print("\nğŸ‰ æ‰€æœ‰æŒ‡æ ‡è¾¾æ ‡ï¼å‡†å¤‡è¿›å…¥ä¸‹ä¸€é˜¶æ®µ")
    print("\nğŸ“š ä¸‹ä¸€æ­¥:")
    print("  1ï¸âƒ£  è¿è¡Œæ¨¡æ‹Ÿç¯å¢ƒæµ‹è¯•")
    print("  2ï¸âƒ£  å¡«å†™é¡¹ç›®è¿›åº¦æ¸…å•")
    print("  3ï¸âƒ£  å‡†å¤‡ ROS2 é›†æˆ")
else:
    print("\nâš ï¸  éƒ¨åˆ†æŒ‡æ ‡æœªè¾¾æ ‡ï¼Œä½†å¯ä»¥ç»§ç»­")

print("\nâœ… å®Œæ•´æµ‹è¯•å®Œæˆï¼")
print("=" * 60)

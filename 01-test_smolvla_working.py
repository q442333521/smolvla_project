"""
SmolVLA å®Œæ•´å·¥ä½œç‰ˆæœ¬
"""

import torch
import numpy as np
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
from transformers import AutoTokenizer
import time

print("ğŸš€ SmolVLA æ¨ç†æµ‹è¯•\n")

# åŠ è½½æ¨¡å‹
print("åŠ è½½æ¨¡å‹...")
policy = SmolVLAPolicy.from_pretrained("lerobot/smolvla_base")
policy = policy.to("cuda").half().eval()
print(f"âœ… æ¨¡å‹åŠ è½½ ({sum(p.numel() for p in policy.parameters()) / 1e6:.1f}Må‚æ•°)\n")

# åŠ è½½tokenizer
tokenizer = AutoTokenizer.from_pretrained(policy.config.vlm_model_name)
print("âœ… TokenizeråŠ è½½\n")

# å‡†å¤‡è¾“å…¥
image = torch.rand(1, 3, 256, 256).cuda().half()
state = torch.randn(1, 7).cuda().half()
instruction = "pick up the red cube"

# TokenåŒ–ï¼ˆå…³é”®ï¼šéœ€è¦attention_maskï¼ï¼‰
tokens = tokenizer(
    instruction,
    return_tensors="pt",
    padding="max_length",
    truncation=True,
    max_length=77
)

observation = {
    "observation.images.camera1": image,
    "observation.state": state,
    "observation.language.tokens": tokens["input_ids"].cuda(),
    "observation.language.attention_mask": tokens["attention_mask"].cuda(),  # â† å…³é”®ï¼
}

print(f"è¾“å…¥ï¼šå›¾åƒ{image.shape}, çŠ¶æ€{state.shape}, æŒ‡ä»¤'{instruction}'\n")

# æ¨ç†
print("æ¨ç†ä¸­...")
start = time.time()

with torch.no_grad():
    actions = policy.select_action(observation)

t = (time.time() - start) * 1000

print(f"âœ… æ¨ç†æˆåŠŸï¼")
print(f"   æ—¶é—´: {t:.1f}ms")
print(f"   è¾“å‡º: {actions.shape}")
print(f"   èŒƒå›´: [{actions.min().item():.3f}, {actions.max().item():.3f}]\n")

# é€Ÿåº¦æµ‹è¯•
print("é€Ÿåº¦æµ‹è¯•ï¼ˆ10æ¬¡ï¼‰...")
times = []
for i in range(10):
    obs = {
        "observation.images.camera1": torch.rand(1, 3, 256, 256).cuda().half(),
        "observation.state": torch.randn(1, 7).cuda().half(),
        "observation.language.tokens": tokens["input_ids"].cuda(),
        "observation.language.attention_mask": tokens["attention_mask"].cuda(),
    }
    
    start = time.time()
    with torch.no_grad():
        _ = policy.select_action(obs)
    times.append((time.time() - start) * 1000)

times = np.array(times)
print(f"âœ… å¹³å‡: {times.mean():.1f}ms, é¢‘ç‡: {1000/times.mean():.1f}Hz\n")

# æ˜¾å­˜
mem = torch.cuda.memory_allocated() / 1024**3
print(f"ğŸ’¾ æ˜¾å­˜: {mem:.2f}GB\n")

# æ€»ç»“
print("=" * 50)
print("ğŸ“Š æ€§èƒ½æ€»ç»“")
print("=" * 50)
print(f"æ¨ç†é€Ÿåº¦: {times.mean():.1f}ms", end="")
if times.mean() < 150:
    print(" âœ… (<150ms)")
else:
    print(f" âš ï¸  (ç›®æ ‡<150ms)")

print(f"æ˜¾å­˜å ç”¨: {mem:.2f}GB", end="")
if mem < 8:
    print(" âœ… (<8GB)")
else:
    print(" âš ï¸  (ç›®æ ‡<8GB)")

if times.mean() < 150 and mem < 8:
    print("\nğŸ‰ æ‰€æœ‰æŒ‡æ ‡è¾¾æ ‡ï¼å¯ä»¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µ")
else:
    print("\nç»§ç»­ä¼˜åŒ–æˆ–ç›´æ¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µ")

print("\nğŸ“š ä¸‹ä¸€æ­¥: è¿è¡Œæ¨¡æ‹Ÿç¯å¢ƒæµ‹è¯•")

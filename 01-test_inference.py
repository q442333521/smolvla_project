"""
SmolVLA æœ¬åœ°æ¨ç†æµ‹è¯•è„šæœ¬ v2ï¼ˆå®Œå…¨ä¿®å¤ç‰ˆï¼‰
"""

import torch
import numpy as np
from PIL import Image
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
from torchvision import transforms
import time

def test_model_loading():
    """æµ‹è¯•1ï¼šæ¨¡å‹åŠ è½½"""
    print("=" * 60)
    print("æµ‹è¯•1ï¼šåŠ è½½SmolVLAé¢„è®­ç»ƒæ¨¡å‹")
    print("=" * 60)
    
    try:
        print("æ­£åœ¨ä¸‹è½½æ¨¡å‹...")
        policy = SmolVLAPolicy.from_pretrained("lerobot/smolvla_base")
        
        # ç§»åˆ°GPUå¹¶è½¬æ¢ç²¾åº¦
        policy = policy.to("cuda")
        policy = policy.half()
        policy.eval()
        
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"   æ¨¡å‹è®¾å¤‡: {next(policy.parameters()).device}")
        print(f"   æ¨¡å‹ç²¾åº¦: {next(policy.parameters()).dtype}")
        
        # æ‰“å°æ¨¡å‹æœŸæœ›çš„ç›¸æœºé…ç½®
        print(f"   æœŸæœ›çš„ç›¸æœº: {list(policy.config.input_features.keys())}")
        
        # ç»Ÿè®¡å‚æ•°é‡
        total_params = sum(p.numel() for p in policy.parameters())
        print(f"   æ€»å‚æ•°é‡: {total_params / 1e6:.2f}M")
        
        return policy
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise

def pil_to_tensor(pil_image, size=(256, 256)):
    """å°†PILå›¾åƒè½¬æ¢ä¸ºæ¨¡å‹éœ€è¦çš„tensoræ ¼å¼"""
    transform = transforms.Compose([
        transforms.Resize(size),
        transforms.ToTensor(),  # è½¬ä¸º (C, H, W) æ ¼å¼ï¼ŒèŒƒå›´ [0, 1]
    ])
    return transform(pil_image)

def test_dummy_inference_simple(policy):
    """æµ‹è¯•2ï¼šè™šæ‹Ÿæ•°æ®æ¨ç†ï¼ˆç®€å•ç‰ˆï¼‰"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•2ï¼šè™šæ‹Ÿæ•°æ®æ¨ç†ï¼ˆTensorè¾“å…¥ï¼‰")
    print("=" * 60)
    
    try:
        # æ–¹æ³•1ï¼šç›´æ¥åˆ›å»ºtensorï¼ˆæœ€ç®€å•ï¼‰
        dummy_image = torch.rand(3, 256, 256).cuda().half()
        dummy_state = torch.randn(7).cuda().half()
        
        # ä½¿ç”¨æ¨¡å‹æœŸæœ›çš„é”®å
        observation = {
            "observation.images.camera1": dummy_image,
            "observation.state": dummy_state,
        }
        
        print(f"   å›¾åƒå½¢çŠ¶: {dummy_image.shape}")
        print(f"   çŠ¶æ€ç»´åº¦: {dummy_state.shape}")
        
        # æ¨ç†
        print("   å¼€å§‹æ¨ç†...")
        start_time = time.time()
        
        with torch.no_grad():
            actions = policy.select_action(observation)
        
        inference_time = time.time() - start_time
        
        print(f"âœ… æ¨ç†æˆåŠŸ")
        print(f"   æ¨ç†æ—¶é—´: {inference_time * 1000:.2f}ms")
        print(f"   è¾“å‡ºå½¢çŠ¶: {actions.shape}")
        print(f"   åŠ¨ä½œèŒƒå›´: [{actions.min().item():.3f}, {actions.max().item():.3f}]")
        
        return actions
        
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise

def test_pil_image_inference(policy):
    """æµ‹è¯•3ï¼šPILå›¾åƒæ¨ç†"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•3ï¼šPILå›¾åƒæ¨ç†")
    print("=" * 60)
    
    try:
        # åˆ›å»ºPILå›¾åƒ
        pil_image = Image.fromarray(
            np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)
        )
        
        # è½¬æ¢ä¸ºtensor
        image_tensor = pil_to_tensor(pil_image).cuda().half()
        dummy_state = torch.randn(7).cuda().half()
        
        observation = {
            "observation.images.camera1": image_tensor,
            "observation.state": dummy_state,
        }
        
        print(f"   PILå›¾åƒå°ºå¯¸: {pil_image.size}")
        print(f"   è½¬æ¢åå½¢çŠ¶: {image_tensor.shape}")
        
        # æ¨ç†
        start_time = time.time()
        
        with torch.no_grad():
            actions = policy.select_action(observation)
        
        inference_time = time.time() - start_time
        
        print(f"âœ… æ¨ç†æˆåŠŸ")
        print(f"   æ¨ç†æ—¶é—´: {inference_time * 1000:.2f}ms")
        
        return actions
        
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise

def test_multiple_cameras(policy):
    """æµ‹è¯•4ï¼šå¤šç›¸æœºè¾“å…¥"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•4ï¼šå¤šç›¸æœºè¾“å…¥")
    print("=" * 60)
    
    try:
        # åˆ›å»ºå¤šä¸ªç›¸æœºçš„å›¾åƒ
        camera1 = torch.rand(3, 256, 256).cuda().half()
        camera2 = torch.rand(3, 256, 256).cuda().half()
        camera3 = torch.rand(3, 256, 256).cuda().half()
        dummy_state = torch.randn(7).cuda().half()
        
        observation = {
            "observation.images.camera1": camera1,
            "observation.images.camera2": camera2,
            "observation.images.camera3": camera3,
            "observation.state": dummy_state,
        }
        
        print(f"   ç›¸æœºæ•°é‡: 3")
        print(f"   æ¯ä¸ªç›¸æœºå½¢çŠ¶: {camera1.shape}")
        
        # æ¨ç†
        start_time = time.time()
        
        with torch.no_grad():
            actions = policy.select_action(observation)
        
        inference_time = time.time() - start_time
        
        print(f"âœ… æ¨ç†æˆåŠŸ")
        print(f"   æ¨ç†æ—¶é—´: {inference_time * 1000:.2f}ms")
        
        return actions
        
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise

def test_gpu_memory():
    """æµ‹è¯•5ï¼šæ˜¾å­˜ä½¿ç”¨"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•5ï¼šGPUæ˜¾å­˜ä½¿ç”¨")
    print("=" * 60)
    
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        total = torch.cuda.get_device_properties(0).total_memory / 1024**3
        
        print(f"   å·²åˆ†é…: {allocated:.2f} GB")
        print(f"   å·²é¢„ç•™: {reserved:.2f} GB")
        print(f"   æ€»æ˜¾å­˜: {total:.2f} GB")
        print(f"   ä½¿ç”¨ç‡: {(allocated / total) * 100:.1f}%")
        
        if allocated < 8.0:
            print("âœ… æ˜¾å­˜ä½¿ç”¨æ­£å¸¸")
        else:
            print("âš ï¸  æ˜¾å­˜ä½¿ç”¨è¾ƒé«˜")

def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("\n" + "ğŸš€" * 30)
    print("SmolVLA æœ¬åœ°æ¨ç†å®Œæ•´æµ‹è¯• v2")
    print("ğŸš€" * 30 + "\n")
    
    try:
        # æµ‹è¯•1: åŠ è½½æ¨¡å‹
        policy = test_model_loading()
        
        # æµ‹è¯•2: Tensorè¾“å…¥æ¨ç†
        test_dummy_inference_simple(policy)
        
        # æµ‹è¯•3: PILå›¾åƒæ¨ç†
        test_pil_image_inference(policy)
        
        # æµ‹è¯•4: å¤šç›¸æœº
        test_multiple_cameras(policy)
        
        # æµ‹è¯•5: æ˜¾å­˜
        test_gpu_memory()
        
        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("=" * 60)
        
    except Exception as e:
        print("\n" + "=" * 60)
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        print("=" * 60)
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
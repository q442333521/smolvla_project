# SmolVLA SO100 Pick-Place 测试结果总结

## 测试概述

**测试日期**: 2024-10-31  
**数据集**: `lerobot/svla_so100_pickplace`  
**模型**: `lerobot/smolvla_base` (未微调的基础模型)  
**测试样本**: 100  
**设备**: CUDA (GPU)

---

## 关键发现：尺度匹配问题

### 问题历程

#### 第一次测试（未反归一化）
- **MAE**: 80.29°
- **预测值范围**: [-1.63, 3.91] ← 归一化值
- **真实值范围**: [-0.70, 177.19] ← 原始角度值
- **结论**: 尺度不匹配！

#### 修复后（添加反归一化）
- **MAE**: 30.42°
- **预测值范围**: [1.57, 162.72] ← 反归一化后
- **真实值范围**: [-0.70, 177.19]
- **改善**: **62% 误差降低** ✅

---

## 测试结果

### 整体性能指标

| 指标 | 值 | 评估 |
|------|-----|------|
| **平均推理时间** | 13.90ms | ✅ 优秀 |
| **整体 MAE** | 30.42° | ⚠️ 一般 |
| **整体 MSE** | 1184.27 | ⚠️ 一般 |
| **最大误差** | 65.18° | ⚠️ 偏高 |

### 各关节性能

| 关节 | 名称 | MAE (度) | 评估 |
|------|------|----------|------|
| 0 | Shoulder Pan | 41.51 | ⚠️ 较高 |
| 1 | Shoulder Lift | 37.97 | ⚠️ 较高 |
| 2 | Elbow | 26.07 | ⚠️ 中等 |
| 3 | Wrist Flex | **16.12** | ✅ 最好 |
| 4 | Wrist Roll | 27.62 | ⚠️ 中等 |
| 5 | Gripper | 33.25 | ⚠️ 较高 |

---

## 数据集统计信息

### 归一化参数

**均值 (mean)**:
```
[14.51, 146.45, 143.32, 62.96, 85.83, 7.78]
```

**标准差 (std)**:
```
[27.99, 34.99, 21.46, 16.91, 12.48, 9.55]
```

### 数据范围

| 关节 | 最小值 | 最大值 | 范围 |
|------|--------|--------|------|
| 0 | -37.18 | 72.77 | 109.95° |
| 1 | 48.87 | 179.47 | 130.60° |
| 2 | 40.96 | 164.62 | 123.66° |
| 3 | 9.67 | 96.59 | 86.92° |
| 4 | 56.25 | 123.57 | 67.32° |
| 5 | 0.00 | 34.93 | 34.93° |

---

## 性能分析

### ✅ 优势

1. **推理速度快**: 13.90ms/样本，适合实时应用
2. **尺度正确**: 反归一化后预测值在合理范围内
3. **所有关节工作**: 没有完全失效的关节
4. **任务描述匹配**: 数据集中使用的正是 "Pick up the cube and place it in the box."

### ⚠️ 问题

1. **整体误差偏高**: MAE=30.42°，远高于预期的 <5°
2. **关节间差异大**: 关节3最好(16°)，关节0最差(41°)
3. **系统性偏差**: 从样本来看，预测值系统性地偏离真实值

### 典型误差示例（样本0）

```
预测值(反归一化): [32.87, 152.78, 131.73,  71.46, 114.12,   1.57]
真实值:           [ 0.62, 177.19, 164.62,  72.33,  82.53,   0.11]
误差:             [32.25, -24.41, -32.89,  -0.87,  31.59,   1.47]
```

- 关节0: 预测过高 (+32.25°)
- 关节1: 预测偏低 (-24.41°)
- 关节2: 预测偏低 (-32.89°)
- 关节3: 几乎完美 (-0.87°) ✅
- 关节4: 预测过高 (+31.59°)
- 关节5: 预测过高 (+1.47°)

---

## 可能的原因

### 1. 模型是基础版本（未微调）

- 我们测试的是 `lerobot/smolvla_base`
- 这是在 481 个社区数据集上预训练的基础模型
- **未针对 SO100 pick-place 任务进行微调**

论文中报告的 78.3% 成功率是在**微调后**的模型上测试的。

### 2. 评估指标不同

- 我们的指标: **MAE** (平均绝对误差，度)
- 论文指标: **成功率** (任务完成率，%)

直接的角度误差不一定等同于任务失败。即使有 30° 的平均误差，机器人仍可能完成任务。

### 3. Action Chunk 使用

模型输出 action chunk（3个时间步）：
```
输出形状: [1, 18] = [1, 3 * 6]
```

我们只取了第一个时间步：
```python
pred_action = output[0, :6]  # 只用了前6个值
```

可能应该：
- 使用整个 action chunk 进行评估
- 或者使用滑动窗口平均

### 4. 测试样本来自训练集

我们测试的前 100 个样本可能就是训练样本。应该：
- 使用 episode split（训练集/测试集分离）
- 或者测试最后的 N 个样本

---

## 与 PushT 测试对比

| 指标 | PushT (修复前) | PushT (修复后) | SO100 (修复后) |
|------|---------------|---------------|---------------|
| **数据集匹配** | ❌ 未见过 | ❌ 未见过 | ✅ 预训练数据 |
| **MAE** | - | 103.42 像素 | 30.42° |
| **性能** | 极差 | 差 | 一般 |
| **原因** | 尺度+任务不匹配 | 任务不匹配 | 未微调 |

---

## 结论

### 主要收获

1. ✅ **归一化处理至关重要**: 
   - 模型输出归一化值
   - 必须使用数据集统计信息反归一化
   - 尺度不匹配会导致巨大误差

2. ✅ **模型基本工作正常**:
   - 推理速度快 (13.90ms)
   - 输出值在合理范围内
   - 各关节都有响应

3. ⚠️ **Base 模型性能有限**:
   - MAE=30.42° 对于预训练数据偏高
   - 需要针对特定任务微调
   - 论文中的高性能是微调后的结果

### 建议下一步

#### 优先级1: 使用微调模型测试

寻找已经在 SO100 pick-place 上微调的模型：
```bash
# 在 HuggingFace 上搜索
# 关键词: smolvla so100 pickplace finetune
```

#### 优先级2: 改进测试方法

1. **使用测试集**: 避免测试训练样本
2. **Action Chunk 评估**: 考虑整个动作序列
3. **任务成功率**: 而不只是角度误差

#### 优先级3: 自己微调模型

如果想在 SO100 上获得更好性能：
```bash
python lerobot/scripts/train.py \
  --policy.path=lerobot/smolvla_base \
  --dataset.repo_id=lerobot/svla_so100_pickplace \
  --batch_size=64 \
  --steps=20000
```

预计训练时间: ~4小时 (A100)

---

## 技术细节

### 反归一化公式

```python
# 模型输出 (归一化值)
pred_norm = policy.select_action(batch)[0, :6]

# 反归一化
pred_denorm = pred_norm * action_std + action_mean

# 与真实值比较
true_action = sample['action']
error = pred_denorm - true_action
```

### 数据集结构

```python
sample = {
    'observation.images.top': [3, 480, 640],      # 俯视相机
    'observation.images.wrist': [3, 480, 640],    # 腕部相机
    'observation.state': [6],                      # 当前关节状态
    'action': [6],                                 # 目标关节位置
    'task': "Pick up the cube and place it in the box."
}
```

### 模型输入要求

```python
batch = {
    'observation.images.camera1': top_image,      # 256x256
    'observation.images.camera2': wrist_image,    # 256x256
    'observation.images.camera3': wrist_image,    # 256x256 (重复)
    'observation.state': state,                   # [1, 6]
    'observation.language.tokens': tokens,        # [1, seq_len]
    'observation.language.attention_mask': mask   # [1, seq_len]
}
```

---

## 参考文件

- 测试脚本: `10-test_so100_pickplace.py`
- 可视化结果: `so100_pickplace_result_fixed.png`
- 数据集: https://huggingface.co/datasets/lerobot/svla_so100_pickplace
- 模型: https://huggingface.co/lerobot/smolvla_base

---

*测试完成时间: 2024-10-31*
*总测试时长: ~5分钟*

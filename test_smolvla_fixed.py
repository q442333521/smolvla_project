"""
SmolVLA ä¿®å¤ç‰ˆæœ¬ - è§£å†³ attention_mask ç±»å‹é—®é¢˜
"""

import torch
import numpy as np
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
from transformers import AutoTokenizer
import time

print("ğŸš€ SmolVLA æ¨ç†æµ‹è¯• (ä¿®å¤ç‰ˆ)\n")

# åŠ è½½æ¨¡å‹
print("åŠ è½½æ¨¡å‹...")
policy = SmolVLAPolicy.from_pretrained("lerobot/smolvla_base")
policy = policy.to("cuda").half().eval()
print(f"âœ… æ¨¡å‹åŠ è½½ ({sum(p.numel() for p in policy.parameters()) / 1e6:.1f}Må‚æ•°)\n")

# åŠ è½½tokenizer
tokenizer = AutoTokenizer.from_pretrained(policy.config.vlm_model_name)
print("âœ… TokenizeråŠ è½½\n")

# å‡†å¤‡è¾“å…¥
image = torch.rand(1, 3, 256, 256).cuda().half()
state = torch.randn(1, 7).cuda().half()
instruction = "pick up the red cube"

# TokenåŒ–
tokens = tokenizer(
    instruction,
    return_tensors="pt",
    padding="max_length",
    truncation=True,
    max_length=77
)

# å…³é”®ä¿®å¤ï¼šå°† attention_mask è½¬æ¢ä¸ºå¸ƒå°”ç±»å‹
observation = {
    "observation.images.camera1": image,
    "observation.state": state,
    "observation.language.tokens": tokens["input_ids"].cuda(),
    "observation.language.attention_mask": tokens["attention_mask"].cuda().bool(),  # â† ä¿®å¤ï¼šè½¬ä¸ºbool!
}

print(f"è¾“å…¥ï¼š")
print(f"  å›¾åƒ: {image.shape}, dtype: {image.dtype}")
print(f"  çŠ¶æ€: {state.shape}, dtype: {state.dtype}")
print(f"  æŒ‡ä»¤: '{instruction}'")
print(f"  tokens: {tokens['input_ids'].shape}")
print(f"  attention_mask: {tokens['attention_mask'].shape}, dtype: bool âœ…\n")

# æ¨ç†
print("æ¨ç†ä¸­...")
start = time.time()

with torch.no_grad():
    actions = policy.select_action(observation)

t = (time.time() - start) * 1000

print(f"âœ… æ¨ç†æˆåŠŸï¼")
print(f"   æ—¶é—´: {t:.1f}ms")
print(f"   è¾“å‡º: {actions.shape}")
print(f"   èŒƒå›´: [{actions.min().item():.3f}, {actions.max().item():.3f}]\n")

# é€Ÿåº¦æµ‹è¯•
print("é€Ÿåº¦æµ‹è¯•ï¼ˆ10æ¬¡ï¼‰...")
times = []
for i in range(10):
    obs = {
        "observation.images.camera1": torch.rand(1, 3, 256, 256).cuda().half(),
        "observation.state": torch.randn(1, 7).cuda().half(),
        "observation.language.tokens": tokens["input_ids"].cuda(),
        "observation.language.attention_mask": tokens["attention_mask"].cuda().bool(),  # ä¿®å¤
    }
    
    start = time.time()
    with torch.no_grad():
        _ = policy.select_action(obs)
    times.append((time.time() - start) * 1000)
    
    if (i + 1) % 5 == 0:
        print(f"  å®Œæˆ {i+1}/10...")

times = np.array(times)
print(f"\nâœ… å¹³å‡: {times.mean():.1f}ms, é¢‘ç‡: {1000/times.mean():.1f}Hz")
print(f"   ä¸­ä½æ•°: {np.median(times):.1f}ms")
print(f"   æ ‡å‡†å·®: {times.std():.1f}ms\n")

# æ˜¾å­˜
mem = torch.cuda.memory_allocated() / 1024**3
print(f"ğŸ’¾ æ˜¾å­˜: {mem:.2f}GB\n")

# æ€»ç»“
print("=" * 60)
print("ğŸ“Š æ€§èƒ½æ€»ç»“")
print("=" * 60)
print(f"æ¨ç†é€Ÿåº¦: {times.mean():.1f}ms", end="")
if times.mean() < 150:
    print(" âœ… è¾¾æ ‡ (<150ms)")
else:
    print(f" âš ï¸  æœªè¾¾æ ‡ (ç›®æ ‡<150ms)")

print(f"æ¨ç†é¢‘ç‡: {1000/times.mean():.1f}Hz", end="")
if 1000/times.mean() > 7:
    print(" âœ… è¾¾æ ‡ (>7Hz)")
else:
    print(" âš ï¸  æœªè¾¾æ ‡ (ç›®æ ‡>7Hz)")

print(f"æ˜¾å­˜å ç”¨: {mem:.2f}GB", end="")
if mem < 8:
    print(" âœ… è¾¾æ ‡ (<8GB)")
else:
    print(" âš ï¸  æœªè¾¾æ ‡ (ç›®æ ‡<8GB)")

print("\næ€§èƒ½ç­‰çº§: ", end="")
if times.mean() < 100 and mem < 6:
    print("ä¼˜ç§€ (A)")
elif times.mean() < 150 and mem < 8:
    print("è‰¯å¥½ (B)")
elif times.mean() < 200:
    print("åŠæ ¼ (C)")
else:
    print("éœ€è¦ä¼˜åŒ– (D)")

if times.mean() < 150 and mem < 8:
    print("\nğŸ‰ æ‰€æœ‰æŒ‡æ ‡è¾¾æ ‡ï¼å¯ä»¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µ")
    print("\nğŸ“š ä¸‹ä¸€æ­¥:")
    print("  1. è¿è¡Œæ¨¡æ‹Ÿç¯å¢ƒæµ‹è¯•")
    print("  2. æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("  3. ROS2é›†æˆå‡†å¤‡")
else:
    print("\nç»§ç»­ä¼˜åŒ–æˆ–ç›´æ¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µ")

print("\n" + "=" * 60)

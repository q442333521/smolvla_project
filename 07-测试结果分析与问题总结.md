# SmolVLA 可视化测试结果分析与问题总结

## 测试脚本概述

**文件**: `05-test_with_visualization_complete.py`

### 脚本功能
该脚本在 PushT 数据集上测试 SmolVLA 模型，并生成可视化分析报告。

### 主要步骤

1. **加载数据集**: 使用 `LeRobotDataset("lerobot/pusht")` 加载 25650 个样本
2. **加载模型**: 加载预训练的 `SmolVLAPolicy` 和 `SmolVLM-Instruct` tokenizer
3. **推理测试**: 对前 100 个样本进行推理，记录时间和结果
4. **计算指标**: 计算 MSE 和 MAE
5. **生成可视化**: 创建 6 个子图的综合分析报告

### 可视化内容

1. **推理性能统计**: 最小/平均/中位数/最大/P95 推理时间
2. **动作轨迹对比 (X维度)**: 预测 vs 真实值
3. **动作轨迹对比 (Y维度)**: 预测 vs 真实值
4. **各维度MSE分布**: 每个动作维度的误差
5. **散点图 (维度0)**: 预测vs真实的相关性
6. **散点图 (维度1)**: 预测vs真实的相关性

---

## 核心问题：尺度不匹配

### 问题描述

测试输出的指标异常：
- **MSE**: 77581.78
- **MAE**: 263.01

经过详细分析发现**根本原因**：

### 数值范围对比

| 类型 | 维度0 | 维度1 |
|------|-------|-------|
| **预测值** | -0.84 ~ 1.37 | -0.09 ~ 1.37 |
| **真实值** | 229 ~ 294 | 71 ~ 127 |
| **误差** | ~230 ~ 295 | ~71 ~ 126 |

### 原因分析

1. **模型输出**: 归一化后的动作值（通常在 [-1, 1] 或 [0, 1] 范围）
2. **数据集动作**: PushT 的原始像素坐标（范围 [0, 512]）
3. **直接比较**: 脚本直接比较了两种不同尺度的值

### 示例数据

```
样本 0:
  预测: [  0.1919,   0.2098]   ← 归一化值
  真实: [233.0000,  71.0000]   ← 像素坐标
  误差: [232.8081,  70.7902]   ← 巨大误差！

样本 5:
  预测: [ -0.8185,   1.3181]
  真实: [251.0000,  95.0000]
  误差: [251.8185,  93.6819]
```

---

## 修复方案

### 方案1: 反归一化预测值 ✅ 推荐

使用数据集的统计信息将模型输出反归一化到原始尺度：

```python
# 假设数据集有统计信息
mean = dataset.stats['action']['mean']
std = dataset.stats['action']['std']

# 反归一化
pred_action = output[0, :2].cpu().numpy()
pred_action_denorm = pred_action * std + mean

# 与原始真实值比较
true_action = sample['action'].cpu().numpy()
```

### 方案2: 归一化真实值

将真实值归一化到模型输出的尺度：

```python
# 归一化真实值
true_action = sample['action'].cpu().numpy()
true_action_norm = (true_action - mean) / std

# 与模型输出比较
pred_action = output[0, :2].cpu().numpy()
```

### 方案3: 使用相对指标

计算归一化后的相对误差：

```python
# 计算相对误差百分比
relative_error = np.abs(pred - true) / (np.abs(true) + 1e-6) * 100
```

---

## 推理性能

✅ **性能良好**

- **平均推理时间**: 14.01ms
- **吞吐量**: ~71 样本/秒
- **性能稳定**: Min=13.4ms, Max=15.2ms

---

## 模型输入输出

### 输入要求

```python
batch = {
    'observation.images.camera1': image,      # [1, 3, 256, 256]
    'observation.images.camera2': image,      # [1, 3, 256, 256]
    'observation.images.camera3': image,      # [1, 3, 256, 256]
    'observation.state': state,               # [1, state_dim]
    'observation.language.tokens': tokens,     # [1, seq_len]
    'observation.language.attention_mask': mask  # [1, seq_len] (bool)
}
```

### 输出格式

```python
output.shape = [1, 6]  # [batch, action_chunk_size * action_dim]
# 对于 PushT (action_dim=2):
#   output[0, 0:2] - 第1个时间步
#   output[0, 2:4] - 第2个时间步  
#   output[0, 4:6] - 第3个时间步
```

---

## 关键发现

1. ✅ **模型正常工作**: 推理速度快，输出格式正确
2. ❌ **指标计算错误**: 比较了不同尺度的值
3. ⚠️ **需要归一化处理**: 必须统一预测值和真实值的尺度
4. ✅ **可视化成功生成**: 但图表显示的是错误的误差

---

## 后续改进

### 优先级高

1. **添加反归一化逻辑**: 将模型输出转换回原始尺度
2. **重新计算指标**: 基于正确尺度的MSE/MAE
3. **更新可视化**: 确保图表显示有意义的误差范围

### 优先级中

4. **添加数据验证**: 检查数值范围是否合理
5. **支持其他数据集**: ALOHA, LIBERO 等
6. **添加更多指标**: 成功率、轨迹相似度等

### 优先级低

7. **性能优化**: 批处理推理
8. **实时可视化**: 在推理过程中显示进度

---

## 经验总结

### ✅ 正确做法

1. 使用 `LeRobotDataset` 加载完整数据
2. 正确处理多相机输入要求
3. tokenizer 生成 tokens 和 attention_mask
4. attention_mask 转换为布尔类型
5. 只取动作的前 N 维匹配任务

### ❌ 错误做法

1. ~~直接比较归一化和非归一化的值~~
2. ~~忽略数据集的统计信息~~
3. ~~不验证数值范围的合理性~~

---

## 结论

虽然测试脚本**成功运行**，但**指标计算不正确**。核心问题是**尺度不匹配**：

- 模型输出：归一化值 (±1)
- 数据集动作：像素坐标 (0-512)

需要**添加反归一化步骤**才能正确评估模型性能。当前的 MSE=77581 和 MAE=263 **没有实际意义**，仅反映了尺度差异。

正确处理后，预期：
- MSE: < 100 (像素^2)
- MAE: < 10 (像素)

---

*分析完成时间: 2024-10-30*

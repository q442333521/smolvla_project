# å¦‚ä½•ä½¿ç”¨ä¸‹è½½çš„æ•°æ®é›†æµ‹è¯• SmolVLA

## ğŸ“‹ å¿«é€Ÿå›ç­”ä½ çš„é—®é¢˜

### 1. `02-test_final_working.py` çš„ä½œç”¨ï¼Ÿ

**ä½œç”¨**: éªŒè¯ SmolVLA æ¨¡å‹èƒ½æ­£å¸¸å·¥ä½œçš„æœ€å°å¯ç”¨ç¤ºä¾‹

**åŒ…å«å†…å®¹**:
- âœ… æ­£ç¡®çš„æ¨¡å‹åŠ è½½æ–¹å¼
- âœ… æ‰€æœ‰å…³é”®bugä¿®å¤
- âœ… æ­£ç¡®çš„è¾“å…¥æ ¼å¼
- âœ… æ€§èƒ½æµ‹è¯•

**ä»€ä¹ˆæ—¶å€™ç”¨**: 
- é¦–æ¬¡å®‰è£…åéªŒè¯ç¯å¢ƒ
- æµ‹è¯•æ¨¡å‹æ˜¯å¦èƒ½æ¨ç†
- å­¦ä¹ æ­£ç¡®çš„ API ä½¿ç”¨æ–¹å¼

---

### 2. å¦‚ä½•ç”¨ä¸‹è½½çš„æ•°æ®é›†å¤ç° SmolVLAï¼Ÿ

## âœ… å®Œæ•´æµç¨‹ï¼ˆåˆšæ‰æˆ‘ä»¬åšçš„ï¼‰

### æ­¥éª¤1: ç†è§£æ•°æ®é›†ç»“æ„

LeRobot æ•°æ®é›†ç»“æ„ï¼š
```
datasets/lerobot_pusht/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ chunk-000/
â”‚       â””â”€â”€ file-000.parquet     â† çŠ¶æ€å’ŒåŠ¨ä½œæ•°æ®
â”œâ”€â”€ videos/
â”‚   â””â”€â”€ observation.images.top/
â”‚       â””â”€â”€ chunk-000/
â”‚           â””â”€â”€ file-000.mp4     â† å›¾åƒæ•°æ®ï¼ˆè§†é¢‘ï¼‰
â””â”€â”€ meta/
    â””â”€â”€ info.json                â† æ•°æ®é›†å…ƒä¿¡æ¯
```

**å…³é”®ç‚¹**:
- **çŠ¶æ€/åŠ¨ä½œ**: å­˜å‚¨åœ¨ Parquet æ–‡ä»¶ä¸­
- **å›¾åƒ**: å­˜å‚¨åœ¨ MP4 è§†é¢‘æ–‡ä»¶ä¸­
- **åˆ†ç¦»å­˜å‚¨**: ä¸åƒä¼ ç»Ÿæ•°æ®é›†å…¨åœ¨ä¸€ä¸ªæ–‡ä»¶

---

### æ­¥éª¤2: è¯»å–æ•°æ®

```python
import pyarrow.parquet as pq
from pathlib import Path

# è¯»å–çŠ¶æ€å’ŒåŠ¨ä½œ
data_file = Path("/root/smolvla_project/datasets/lerobot_pusht/data/chunk-000/file-000.parquet")
df = pq.read_table(data_file).to_pandas()

print(f"æ ·æœ¬æ•°: {len(df)}")  # 25650
print(f"åˆ—å: {df.columns}")  # ['observation.state', 'action', ...]

# è·å–ä¸€ä¸ªæ ·æœ¬
sample = df.iloc[0]
state = sample['observation.state']   # æœºå™¨äººçŠ¶æ€
action = sample['action']             # çœŸå®åŠ¨ä½œ
```

---

### æ­¥éª¤3: å‡†å¤‡ SmolVLA è¾“å…¥

```python
import torch
from transformers import AutoTokenizer

device = "cuda"
tokenizer = AutoTokenizer.from_pretrained("HuggingFaceTB/SmolVLM2-500M-Video-Instruct")

# 1. å¤„ç†çŠ¶æ€ï¼ˆè°ƒæ•´åˆ°14ç»´ï¼‰
state_tensor = torch.tensor(state, dtype=torch.float32)
if len(state_tensor) < 14:
    state_tensor = torch.cat([state_tensor, torch.zeros(14-len(state_tensor))])

# 2. å›¾åƒï¼ˆå¦‚æœæ²¡æœ‰è§†é¢‘ï¼Œç”¨åˆæˆå›¾åƒï¼‰
img = torch.rand(1, 3, 256, 256).to(device)

# 3. è¯­è¨€æŒ‡ä»¤
tokens = tokenizer("Push the block", return_tensors="pt")

# 4. ç»„è£…è¾“å…¥
observation = {
    "observation.images.camera1": img,
    "observation.images.camera2": img.clone(),
    "observation.images.camera3": img.clone(),
    "observation.state": state_tensor.unsqueeze(0).to(device),
    "observation.language.tokens": tokens['input_ids'].to(device),
    "observation.language.attention_mask": tokens['attention_mask'].to(device).bool(),
}
```

---

### æ­¥éª¤4: æ¨ç†

```python
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy

# åŠ è½½æ¨¡å‹
policy = SmolVLAPolicy.from_pretrained("lerobot/smolvla_base")
policy = policy.to(device).float().eval()

# æ¨ç†
with torch.no_grad():
    predicted_action = policy.select_action(observation)

print(f"é¢„æµ‹åŠ¨ä½œ: {predicted_action.shape}")  # (1, 6)
print(f"çœŸå®åŠ¨ä½œ: {action}")
```

---

## ğŸš€ å¿«é€Ÿä½¿ç”¨è„šæœ¬

æˆ‘å·²ç»åˆ›å»ºäº†ç°æˆçš„è„šæœ¬ï¼š

### è„šæœ¬1: `test_final.py` ï¼ˆæœ€ç®€å•ï¼‰âœ…
```bash
python test_final.py
```

**åŠŸèƒ½**:
- ä»æ•°æ®é›†è¯»å–5ä¸ªæ ·æœ¬çš„çŠ¶æ€
- ä½¿ç”¨åˆæˆå›¾åƒï¼ˆå› ä¸ºè§†é¢‘æ–‡ä»¶è·¯å¾„é—®é¢˜ï¼‰
- è¿›è¡Œæ¨ç†æµ‹è¯•
- æ˜¾ç¤ºæ€§èƒ½ç»Ÿè®¡

**è¾“å‡º**:
```
âœ… æ•°æ®: 25650 æ ·æœ¬
âœ… æ¨¡å‹åŠ è½½

æµ‹è¯• 5 ä¸ªæ ·æœ¬:
  [1] 1177.4ms - åŠ¨ä½œ: torch.Size([1, 6])
  [2] 4.3ms - åŠ¨ä½œ: torch.Size([1, 6])
  ...

å¹³å‡: 239.6ms, é¢‘ç‡: 4.2Hz
æ˜¾å­˜: 1.70GB
```

---

### è„šæœ¬2: `test_dataset_fixed.py` ï¼ˆå®Œæ•´ç‰ˆï¼‰
```bash
python test_dataset_fixed.py
```

**åŠŸèƒ½**:
- å°è¯•è¯»å–è§†é¢‘æ–‡ä»¶è·å–çœŸå®å›¾åƒ
- æ‰¹é‡æµ‹è¯•20ä¸ªæ ·æœ¬
- è®¡ç®—ä¸çœŸå®åŠ¨ä½œçš„MSE
- å®Œæ•´çš„æ€§èƒ½ç»Ÿè®¡

---

## ğŸ“Š æµ‹è¯•ç»“æœè§£è¯»

### æˆåŠŸçš„æ ‡å¿—
âœ… æ¨ç†æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶æ­£ç¡® `(1, 6)`
âœ… æ¨ç†æ—¶é—´åˆç†ï¼ˆé¦–æ¬¡ ~1sï¼Œåç»­ ~5msï¼‰
âœ… æ˜¾å­˜ä½¿ç”¨æ­£å¸¸ï¼ˆ~1.7GBï¼‰
âœ… æ— å´©æºƒæˆ–é”™è¯¯

### ä¸ºä»€ä¹ˆé¦–æ¬¡æ¨ç†æ…¢ï¼Ÿ
- é¦–æ¬¡: 1177msï¼ˆæ¨¡å‹åˆå§‹åŒ–ï¼‰
- åç»­: 4-7msï¼ˆä»ç¼“å­˜é˜Ÿåˆ—å–åŠ¨ä½œï¼‰
- **è¿™æ˜¯æ­£å¸¸çš„å¼‚æ­¥æ¨ç†æœºåˆ¶**

### åŠ¨ä½œå½¢çŠ¶å¯¹æ¯”
- é¢„æµ‹: `(1, 6)` - SmolVLA è¾“å‡º6ç»´åŠ¨ä½œ
- çœŸå®: `(2,)` - PushT æ•°æ®é›†æ˜¯2ç»´ï¼ˆx, yï¼‰

**è¿™æ˜¯æ­£å¸¸çš„ï¼** ä¸åŒæ•°æ®é›†åŠ¨ä½œç©ºé—´ä¸åŒã€‚

---

## ğŸ¯ å…³é”®è¦ç‚¹

### 1. LeRobot æ•°æ®é›† â‰  ä¼ ç»Ÿæ•°æ®é›†
- çŠ¶æ€å’Œå›¾åƒ**åˆ†å¼€å­˜å‚¨**
- éœ€è¦**åˆ†åˆ«è¯»å–**å¹¶ç»„åˆ

### 2. SmolVLA è¾“å…¥æ ¼å¼å›ºå®š
```python
å¿…é¡»æä¾›:
- 3ä¸ªç›¸æœºå›¾åƒ (camera1/2/3)
- çŠ¶æ€å‘é‡ (14ç»´)
- è¯­è¨€æŒ‡ä»¤ (tokenized)
- attention_mask (boolç±»å‹ï¼)
```

### 3. é¦–æ¬¡æ¨ç†æ…¢æ˜¯æ­£å¸¸çš„
- SmolVLA ä½¿ç”¨åŠ¨ä½œé˜Ÿåˆ—ç¼“å†²
- é¦–æ¬¡ç”Ÿæˆ50æ­¥åŠ¨ä½œï¼ˆæ…¢ï¼‰
- åç»­ä»é˜Ÿåˆ—å–ï¼ˆå¿«ï¼‰

---

## ğŸ“ ç›¸å…³æ–‡ä»¶

| æ–‡ä»¶ | ä½œç”¨ |
|------|------|
| `02-test_final_working.py` | æœ€å°å¯ç”¨ç¤ºä¾‹ï¼ˆéªŒè¯ç¯å¢ƒï¼‰|
| `test_final.py` | ç”¨æ•°æ®é›†æµ‹è¯•ï¼ˆç®€åŒ–ç‰ˆï¼‰âœ… |
| `test_dataset_fixed.py` | ç”¨æ•°æ®é›†æµ‹è¯•ï¼ˆå®Œæ•´ç‰ˆï¼‰|
| `README_HOW_TO_USE_DATASET.md` | æœ¬æ–‡æ¡£ |

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: è§†é¢‘æ–‡ä»¶è¯»å–å¤±è´¥ï¼Ÿ
**A**: æ­£å¸¸ï¼è§†é¢‘è·¯å¾„å¯èƒ½ä¸åŒï¼Œç”¨åˆæˆå›¾åƒæµ‹è¯•åŠŸèƒ½å³å¯ã€‚

### Q2: åŠ¨ä½œç»´åº¦ä¸åŒ¹é…ï¼Ÿ
**A**: æ­£å¸¸ï¼SmolVLA è¾“å‡ºå›ºå®š6ç»´ï¼Œæ•°æ®é›†å¯èƒ½æ˜¯å…¶ä»–ç»´åº¦ã€‚

### Q3: é¦–æ¬¡æ¨ç†å¾ˆæ…¢ï¼Ÿ
**A**: æ­£å¸¸ï¼SmolVLA é¢„ç”Ÿæˆ50æ­¥åŠ¨ä½œï¼Œé¦–æ¬¡éœ€è¦æ—¶é—´ã€‚

### Q4: MSE å¾ˆå¤§ï¼Ÿ
**A**: æ­£å¸¸ï¼æ²¡æœ‰åœ¨è¿™ä¸ªæ•°æ®é›†ä¸Šå¾®è°ƒï¼Œåªæ˜¯æµ‹è¯•æ¨ç†åŠŸèƒ½ã€‚

---

## âœ… æ€»ç»“

ä½ ç°åœ¨å·²ç»çŸ¥é“å¦‚ä½•ï¼š

1. âœ… **ç†è§£** `02-test_final_working.py` çš„ä½œç”¨ï¼ˆéªŒè¯è„šæœ¬ï¼‰
2. âœ… **åŠ è½½** LeRobot æ•°æ®é›†
3. âœ… **å‡†å¤‡** SmolVLA è¾“å…¥
4. âœ… **è¿è¡Œ** æ¨ç†æµ‹è¯•
5. âœ… **è§£è¯»** æµ‹è¯•ç»“æœ

**ä¸‹ä¸€æ­¥**: 
- å¦‚æœè¦ç”¨çœŸå®å›¾åƒï¼Œéœ€è¦æ­£ç¡®è¯»å–è§†é¢‘æ–‡ä»¶
- å¦‚æœè¦è¯„ä¼°æ€§èƒ½ï¼Œéœ€è¦åœ¨æ•°æ®é›†ä¸Šå¾®è°ƒæ¨¡å‹
- å¦‚æœè¦å®é™…åº”ç”¨ï¼Œåº”è¯¥è¿›å…¥ROS2é›†æˆé˜¶æ®µ

---

**åˆ›å»ºæ—¶é—´**: 2025-10-20  
**æµ‹è¯•ç¯å¢ƒ**: WSL2 + CUDA 12.1 + PyTorch 2.3.0  
**æ•°æ®é›†**: lerobot/pusht (25650 samples)

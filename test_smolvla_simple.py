"""
SmolVLA ç®€å•æµ‹è¯• - Float32
"""

import torch
import numpy as np
from lerobot.policies.smolvla.modeling_smolvla import SmolVLAPolicy
from transformers import AutoTokenizer
import time

print("ğŸš€ SmolVLA æ¨ç†æµ‹è¯•\n")

# åŠ è½½æ¨¡å‹
print("åŠ è½½æ¨¡å‹...")
policy = SmolVLAPolicy.from_pretrained("lerobot/smolvla_base")
policy = policy.to("cuda").float().eval()  # è½¬æ¢ä¸º float32

print(f"âœ… æ¨¡å‹åŠ è½½ ({sum(p.numel() for p in policy.parameters()) / 1e6:.1f}Må‚æ•°)")
print(f"   æ•°æ®ç±»å‹: {next(policy.parameters()).dtype}\n")

# åŠ è½½tokenizer
tokenizer = AutoTokenizer.from_pretrained(policy.config.vlm_model_name)
print("âœ… TokenizeråŠ è½½\n")

# å‡†å¤‡è¾“å…¥
image = torch.rand(1, 3, 256, 256).cuda().float()
state = torch.randn(1, 7).cuda().float()
instruction = "pick up the red cube"

# TokenåŒ–
tokens = tokenizer(
    instruction,
    return_tensors="pt",
    padding="max_length",
    truncation=True,
    max_length=77
)

observation = {
    "observation.images.camera1": image,
    "observation.state": state,
    "observation.language.tokens": tokens["input_ids"].cuda(),
    "observation.language.attention_mask": tokens["attention_mask"].cuda().bool(),
}

print(f"è¾“å…¥: å›¾åƒ{image.shape}, çŠ¶æ€{state.shape}, æŒ‡ä»¤'{instruction}'\n")

# æ¨ç†
print("ğŸ”¥ æ¨ç†ä¸­ï¼ˆé¦–æ¬¡è¾ƒæ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼‰...")
start = time.time()

with torch.no_grad():
    actions = policy.select_action(observation)

t = (time.time() - start)

print(f"\nâœ… æ¨ç†æˆåŠŸï¼")
print(f"   æ—¶é—´: {t:.2f}ç§’ ({t*1000:.1f}ms)")
print(f"   è¾“å‡º: {actions.shape}")
print(f"   èŒƒå›´: [{actions.min().item():.3f}, {actions.max().item():.3f}]\n")

# é€Ÿåº¦æµ‹è¯•
print("é€Ÿåº¦æµ‹è¯•ï¼ˆ10æ¬¡ï¼‰...")
times = []
for i in range(10):
    obs = {
        "observation.images.camera1": torch.rand(1, 3, 256, 256).cuda().float(),
        "observation.state": torch.randn(1, 7).cuda().float(),
        "observation.language.tokens": tokens["input_ids"].cuda(),
        "observation.language.attention_mask": tokens["attention_mask"].cuda().bool(),
    }
    
    start = time.time()
    with torch.no_grad():
        _ = policy.select_action(obs)
    times.append((time.time() - start) * 1000)
    
    if (i + 1) % 5 == 0:
        print(f"  {i+1}/10 å®Œæˆ")

times = np.array(times)
print(f"\nâœ… å¹³å‡: {times.mean():.1f}ms, é¢‘ç‡: {1000/times.mean():.1f}Hz")

# æ˜¾å­˜
mem = torch.cuda.memory_allocated() / 1024**3
print(f"ğŸ’¾ æ˜¾å­˜: {mem:.2f}GB\n")

# æ€»ç»“
print("=" * 60)
print("ğŸ“Š ç»“æœ")
print("=" * 60)
print(f"æ¨ç†é€Ÿåº¦: {times.mean():.1f}ms " + ("âœ…" if times.mean() < 150 else "âš ï¸"))
print(f"æ˜¾å­˜å ç”¨: {mem:.2f}GB " + ("âœ…" if mem < 12 else "âš ï¸"))
print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
